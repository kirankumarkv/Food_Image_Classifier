{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMed+5s96ngX7gKOQ9Ij7Qb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kirankumarkv/Food_Image_Classifier/blob/main/Food_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4mKJFr7AttmO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import os.path\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3tk58mEY02n",
        "outputId": "8108c855-ce6a-4131-c58b-12a8af007d8d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/model_weights.h5 /content/drive/MyDrive/.\n"
      ],
      "metadata": {
        "id": "yz_JShp5Y6r8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "image_dir = Path('/content/drive/MyDrive/FoodImage/')\n",
        "\n",
        "image_df = []\n",
        "\n",
        "# Iterate over the subdirectories\n",
        "for subdirectory in image_dir.iterdir():\n",
        "    if subdirectory.is_dir():\n",
        "        label = subdirectory.name  # Use the subdirectory name as the label\n",
        "        # Iterate over the images in the subdirectory\n",
        "        for image_path in subdirectory.glob('*.jpg'):  # Modify the pattern according to your image file extension\n",
        "            filepath = str(image_path)  # Convert the Path object to a string\n",
        "            image_df.append((filepath, label))  # Append the (filepath, label) tuple to the image_df list\n"
      ],
      "metadata": {
        "id": "5caWWYGhZkxt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_df"
      ],
      "metadata": {
        "id": "JVNfW5ruZn34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [label for _, label in image_df]\n",
        "\n",
        "# Count the occurrences of each label\n",
        "label_counts = {}\n",
        "for label in labels:\n",
        "    if label not in label_counts:\n",
        "        label_counts[label] = 0\n",
        "    label_counts[label] += 1\n",
        "\n",
        "# Print the label counts\n",
        "for label, count in label_counts.items():\n",
        "    print(f\"{label}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3K92rpfaSZV",
        "outputId": "a9c6307b-cd9a-4ca6-a133-2022a47426ee"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bread: 90\n",
            "ApplePie: 93\n",
            "FriedRice: 88\n",
            "BagelSandwich: 45\n",
            "Bibimbop: 92\n",
            "Pork: 89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the image_df into train, validation, and test DataFrames\n",
        "train_df, temp_df = train_test_split(image_df, train_size=0.7, shuffle=True, random_state=1)\n",
        "val_df, test_df = train_test_split(temp_df, train_size=0.5, shuffle=True, random_state=1)\n",
        "\n",
        "# Convert train_df, val_df, and test_df to Pandas DataFrames\n",
        "train_df = pd.DataFrame(train_df, columns=['Filepath', 'Label'])\n",
        "val_df = pd.DataFrame(val_df, columns=['Filepath', 'Label'])\n",
        "test_df = pd.DataFrame(test_df, columns=['Filepath', 'Label'])\n",
        "\n",
        "# Set up the image data generator with data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
        "    rotation_range=40,         # Increased rotation range\n",
        "    width_shift_range=0.3,     # Increased width shift range\n",
        "    height_shift_range=0.3,    # Increased height shift range\n",
        "    shear_range=0.2,           # Increased shear range\n",
        "    zoom_range=0.2,            # Increased zoom range\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Flow from dataframe for train data\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col='Filepath',  # Column name containing the filepaths\n",
        "    y_col='Label',  # Column name containing the labels\n",
        "    target_size=(224, 224),  # Adjust the target size as needed\n",
        "    batch_size=32,  # Adjust the batch size as needed\n",
        "    class_mode='categorical',  # Set the class_mode based on your problem\n",
        "    subset='training',  # Specify training subset\n",
        "    shuffle=True,  # Shuffle the data during training\n",
        "    seed=1  # Set a seed for reproducibility\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.inception_v3.preprocess_input\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.inception_v3.preprocess_input\n",
        ")\n",
        "\n",
        "# Flow from dataframe for validation data\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    test_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Flow from dataframe for test data\n",
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    test_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False  # Do not shuffle the data during testing\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf-xTV8sgbyy",
        "outputId": "112b9127-543f-4956-ed7c-04aaf74c99ce"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 347 validated image filenames belonging to 6 classes.\n",
            "Found 75 validated image filenames belonging to 6 classes.\n",
            "Found 75 validated image filenames belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "\n",
        "# Create a InceptionV3 model\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "# Add the pretrained InceptionV3 model as the base\n",
        "pretrained_model = InceptionV3(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "model.add(pretrained_model)\n",
        "\n",
        "# Add more layers to the model\n",
        "model.add(layers.GlobalAveragePooling2D())  # Add GlobalAveragePooling2D to reduce spatial dimensions\n",
        "model.add(layers.Dense(1024, activation='relu'))  # Add a dense layer with 1024 units and ReLU activation\n",
        "model.add(layers.Dropout(0.5))  # Add dropout for regularization\n",
        "model.add(layers.Dense(512, activation='relu'))  # Add another dense layer with 512 units and ReLU activation\n",
        "model.add(layers.Dense(256, activation='relu'))  # Add another dense layer with 256 units and ReLU activation\n",
        "model.add(layers.Dense(6, activation='softmax'))  # Add the output layer with 6 units for your classes and softmax activation\n",
        "\n",
        "# Print the model summary to see the updated architecture\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP7VwSOuu207",
        "outputId": "5a225c66-51fc-48a1-fca7-4d6f7f779f09"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inception_v3 (Functional)   (None, 5, 5, 2048)        21802784  \n",
            "                                                                 \n",
            " global_average_pooling2d_3   (None, 2048)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 6)                 1542      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,558,630\n",
            "Trainable params: 24,524,198\n",
            "Non-trainable params: 34,432\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the ModelCheckpoint callback\n",
        "checkpoint_filepath = '/content/drive/MyDrive/model_weights.h5'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',  # You can choose the metric to monitor for saving weights\n",
        "    mode='min',          # 'min' for loss, 'max' for accuracy, etc.\n",
        "    save_best_only=True  # Only save the best weights based on the monitored metric\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Set the number of steps per epoch and validation steps\n",
        "train_steps_per_epoch = len(train_generator)\n",
        "val_steps = len(test_generator)\n",
        "\n",
        "# Train the model using the data generators\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=50,\n",
        "    steps_per_epoch=train_steps_per_epoch,\n",
        "    validation_steps=val_steps,\n",
        "    callbacks=[\n",
        "        model_checkpoint_callback,  # Add the ModelCheckpoint callback\n",
        "\n",
        "    ]\n",
        "        #tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3,\n",
        "         #   restore_best_weights=True),\n",
        "\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWHfLpHBorXC",
        "outputId": "eed3fa7e-3296-4f8f-f86b-c44c4328216e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "11/11 [==============================] - 82s 3s/step - loss: 1.7076 - accuracy: 0.3314 - val_loss: 3.1800 - val_accuracy: 0.2400\n",
            "Epoch 2/50\n",
            "11/11 [==============================] - 33s 3s/step - loss: 1.1134 - accuracy: 0.6340 - val_loss: 2.1335 - val_accuracy: 0.2533\n",
            "Epoch 3/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.9621 - accuracy: 0.6830 - val_loss: 16.8913 - val_accuracy: 0.2133\n",
            "Epoch 4/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.9481 - accuracy: 0.7147 - val_loss: 3.1931 - val_accuracy: 0.1333\n",
            "Epoch 5/50\n",
            "11/11 [==============================] - 32s 3s/step - loss: 0.9633 - accuracy: 0.7233 - val_loss: 2.9841 - val_accuracy: 0.3200\n",
            "Epoch 6/50\n",
            "11/11 [==============================] - 32s 3s/step - loss: 0.8016 - accuracy: 0.7435 - val_loss: 10.0311 - val_accuracy: 0.3200\n",
            "Epoch 7/50\n",
            "11/11 [==============================] - 32s 3s/step - loss: 0.8216 - accuracy: 0.7550 - val_loss: 4.9432 - val_accuracy: 0.2133\n",
            "Epoch 8/50\n",
            "11/11 [==============================] - 35s 3s/step - loss: 0.9335 - accuracy: 0.7089 - val_loss: 11.4200 - val_accuracy: 0.3200\n",
            "Epoch 9/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.8846 - accuracy: 0.7723 - val_loss: 4.5760 - val_accuracy: 0.2400\n",
            "Epoch 10/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.8696 - accuracy: 0.7147 - val_loss: 46.7165 - val_accuracy: 0.2400\n",
            "Epoch 11/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.6303 - accuracy: 0.7954 - val_loss: 13.4019 - val_accuracy: 0.3600\n",
            "Epoch 12/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.6205 - accuracy: 0.8098 - val_loss: 84.2285 - val_accuracy: 0.2000\n",
            "Epoch 13/50\n",
            "11/11 [==============================] - 32s 3s/step - loss: 0.5287 - accuracy: 0.8386 - val_loss: 1.6068 - val_accuracy: 0.3067\n",
            "Epoch 14/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.6536 - accuracy: 0.8444 - val_loss: 6.9794 - val_accuracy: 0.3867\n",
            "Epoch 15/50\n",
            "11/11 [==============================] - 32s 3s/step - loss: 0.4844 - accuracy: 0.8415 - val_loss: 3.9184 - val_accuracy: 0.4400\n",
            "Epoch 16/50\n",
            "11/11 [==============================] - 32s 3s/step - loss: 0.5928 - accuracy: 0.8213 - val_loss: 3.3809 - val_accuracy: 0.2933\n",
            "Epoch 17/50\n",
            "11/11 [==============================] - 30s 3s/step - loss: 0.4201 - accuracy: 0.8790 - val_loss: 2.6272 - val_accuracy: 0.5067\n",
            "Epoch 18/50\n",
            "11/11 [==============================] - 30s 3s/step - loss: 0.4958 - accuracy: 0.8818 - val_loss: 6.7232 - val_accuracy: 0.5600\n",
            "Epoch 19/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.4832 - accuracy: 0.8530 - val_loss: 18.0683 - val_accuracy: 0.4800\n",
            "Epoch 20/50\n",
            "11/11 [==============================] - 30s 3s/step - loss: 0.3307 - accuracy: 0.9049 - val_loss: 1.6567 - val_accuracy: 0.4400\n",
            "Epoch 21/50\n",
            "11/11 [==============================] - 30s 3s/step - loss: 0.4405 - accuracy: 0.8847 - val_loss: 3.5563 - val_accuracy: 0.6000\n",
            "Epoch 22/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.4259 - accuracy: 0.8703 - val_loss: 1.7374 - val_accuracy: 0.5733\n",
            "Epoch 23/50\n",
            "11/11 [==============================] - 32s 3s/step - loss: 0.4804 - accuracy: 0.8732 - val_loss: 13.7772 - val_accuracy: 0.4933\n",
            "Epoch 24/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.3803 - accuracy: 0.9020 - val_loss: 11.2796 - val_accuracy: 0.5867\n",
            "Epoch 25/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.3471 - accuracy: 0.8991 - val_loss: 2.1637 - val_accuracy: 0.5867\n",
            "Epoch 26/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.3231 - accuracy: 0.9078 - val_loss: 4.5429 - val_accuracy: 0.4533\n",
            "Epoch 27/50\n",
            "11/11 [==============================] - 30s 3s/step - loss: 0.3172 - accuracy: 0.9164 - val_loss: 3.8620 - val_accuracy: 0.6400\n",
            "Epoch 28/50\n",
            "11/11 [==============================] - 30s 3s/step - loss: 0.4524 - accuracy: 0.8790 - val_loss: 2.9367 - val_accuracy: 0.5067\n",
            "Epoch 29/50\n",
            "11/11 [==============================] - 32s 3s/step - loss: 0.4608 - accuracy: 0.8559 - val_loss: 5.7625 - val_accuracy: 0.3733\n",
            "Epoch 30/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.4072 - accuracy: 0.8876 - val_loss: 3.2723 - val_accuracy: 0.3733\n",
            "Epoch 31/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.3262 - accuracy: 0.9164 - val_loss: 2.8413 - val_accuracy: 0.4533\n",
            "Epoch 32/50\n",
            "11/11 [==============================] - 33s 3s/step - loss: 0.5006 - accuracy: 0.8761 - val_loss: 1.0625 - val_accuracy: 0.7733\n",
            "Epoch 33/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.3668 - accuracy: 0.8991 - val_loss: 2.6929 - val_accuracy: 0.5333\n",
            "Epoch 34/50\n",
            "11/11 [==============================] - 33s 3s/step - loss: 0.3291 - accuracy: 0.9280 - val_loss: 0.7509 - val_accuracy: 0.7467\n",
            "Epoch 35/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.2226 - accuracy: 0.9366 - val_loss: 1.6219 - val_accuracy: 0.6800\n",
            "Epoch 36/50\n",
            "11/11 [==============================] - 30s 3s/step - loss: 0.3483 - accuracy: 0.9107 - val_loss: 2.7104 - val_accuracy: 0.4267\n",
            "Epoch 37/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.4460 - accuracy: 0.8934 - val_loss: 1.8612 - val_accuracy: 0.5067\n",
            "Epoch 38/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.4552 - accuracy: 0.8703 - val_loss: 2.0921 - val_accuracy: 0.5067\n",
            "Epoch 39/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.3546 - accuracy: 0.8991 - val_loss: 2.1116 - val_accuracy: 0.6000\n",
            "Epoch 40/50\n",
            "11/11 [==============================] - 30s 3s/step - loss: 0.3071 - accuracy: 0.9049 - val_loss: 3.7949 - val_accuracy: 0.3600\n",
            "Epoch 41/50\n",
            "11/11 [==============================] - 32s 3s/step - loss: 0.3373 - accuracy: 0.8934 - val_loss: 11.0160 - val_accuracy: 0.2667\n",
            "Epoch 42/50\n",
            "11/11 [==============================] - 37s 3s/step - loss: 0.3658 - accuracy: 0.8991 - val_loss: 2.2484 - val_accuracy: 0.5333\n",
            "Epoch 43/50\n",
            "11/11 [==============================] - 30s 3s/step - loss: 0.2725 - accuracy: 0.9193 - val_loss: 1.3355 - val_accuracy: 0.7333\n",
            "Epoch 44/50\n",
            "11/11 [==============================] - 32s 3s/step - loss: 0.2708 - accuracy: 0.8963 - val_loss: 3.2274 - val_accuracy: 0.6400\n",
            "Epoch 45/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.3676 - accuracy: 0.8847 - val_loss: 0.7728 - val_accuracy: 0.7200\n",
            "Epoch 46/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.3723 - accuracy: 0.8991 - val_loss: 0.8169 - val_accuracy: 0.7733\n",
            "Epoch 47/50\n",
            "11/11 [==============================] - 33s 3s/step - loss: 0.2734 - accuracy: 0.9078 - val_loss: 0.9612 - val_accuracy: 0.7200\n",
            "Epoch 48/50\n",
            "11/11 [==============================] - 30s 3s/step - loss: 0.2541 - accuracy: 0.9308 - val_loss: 1.5714 - val_accuracy: 0.6533\n",
            "Epoch 49/50\n",
            "11/11 [==============================] - 32s 3s/step - loss: 0.2215 - accuracy: 0.9424 - val_loss: 1.9073 - val_accuracy: 0.5333\n",
            "Epoch 50/50\n",
            "11/11 [==============================] - 31s 3s/step - loss: 0.2312 - accuracy: 0.9366 - val_loss: 1.6647 - val_accuracy: 0.5867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data generator\n",
        "results = model.evaluate(test_generator, verbose=0)\n",
        "\n",
        "print(\"Test Loss:\", results[0])\n",
        "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJQDY42bvuXl",
        "outputId": "a2f1027b-f927-42c8-abd1-fe5e1a395814"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.6646661758422852\n",
            "Test Accuracy: 58.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Get predictions using the test data generator\n",
        "predictions = np.argmax(model.predict(test_generator), axis=1)\n",
        "\n",
        "# Get true labels from the test data generator\n",
        "true_labels = test_generator.classes\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(true_labels, predictions)\n",
        "\n",
        "# Compute classification report\n",
        "class_names = list(test_generator.class_indices.keys())\n",
        "clr = classification_report(true_labels, predictions, target_names=class_names, zero_division=0)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(clr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHsksWI-psd-",
        "outputId": "b04456d8-212e-451e-dd47-91e3c5a1ad04"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 5s 1s/step\n",
            "Confusion Matrix:\n",
            "[[ 4  0  6  3  0  0]\n",
            " [ 0  5  2  0  0  0]\n",
            " [ 0  0 12  0  0  0]\n",
            " [ 0  1  2 13  0  0]\n",
            " [ 0  3  2  0  7  0]\n",
            " [ 0  3  7  2  0  3]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     ApplePie       1.00      0.31      0.47        13\n",
            "BagelSandwich       0.42      0.71      0.53         7\n",
            "     Bibimbop       0.39      1.00      0.56        12\n",
            "        Bread       0.72      0.81      0.76        16\n",
            "    FriedRice       1.00      0.58      0.74        12\n",
            "         Pork       1.00      0.20      0.33        15\n",
            "\n",
            "     accuracy                           0.59        75\n",
            "    macro avg       0.75      0.60      0.56        75\n",
            " weighted avg       0.79      0.59      0.57        75\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RG8YdlG7ptYu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}